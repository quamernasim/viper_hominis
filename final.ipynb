{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-30 05:53:48.778631: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-30 05:53:49.458502: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-11-30 05:53:49.458566: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-11-30 05:53:49.458572: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "/home/deepkapha/anaconda3/envs/vipergpt/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: /home/deepkapha/anaconda3/envs/vipergpt did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
      "  warn(msg)\n",
      "/home/deepkapha/anaconda3/envs/vipergpt/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('\"en\",\"resolvedLanguage\"'), PosixPath('\"/home/deepkapha/.vscode-server/cli/servers/Stable-f1a4fb101478ce6ec82fe9627c43efbf9e98c813/server/out/nls.messages.json\",\"locale\"'), PosixPath('\"en\",\"osLocale\"'), PosixPath('\"en\",\"availableLanguages\"'), PosixPath('{\"userLocale\"'), PosixPath('\"en\",\"defaultMessagesFile\"'), PosixPath('{}}')}\n",
      "  warn(msg)\n",
      "/home/deepkapha/anaconda3/envs/vipergpt/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/home/deepkapha/mambaforge/envs/pygmt/lib')}\n",
      "  warn(msg)\n",
      "/home/deepkapha/anaconda3/envs/vipergpt/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/var/lib/nvidia-mig-manager/checkpoint.json')}\n",
      "  warn(msg)\n",
      "/home/deepkapha/anaconda3/envs/vipergpt/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('vs/workbench/api/node/extensionHostProcess')}\n",
      "  warn(msg)\n",
      "/home/deepkapha/anaconda3/envs/vipergpt/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('module'), PosixPath('//matplotlib_inline.backend_inline')}\n",
      "  warn(msg)\n",
      "/home/deepkapha/anaconda3/envs/vipergpt/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/usr/local/cuda/lib64/libcudart.so.11.0'), PosixPath('/usr/local/cuda/lib64/libcudart.so')}.. We'll flip a coin and try one of these, in order to fail forward.\n",
      "Either way, this might cause trouble in the future:\n",
      "If you get `CUDA error: invalid device function` errors, the above might be the cause and the solution is to make sure only one ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] in the paths that we search based on your env.\n",
      "  warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /home/deepkapha/anaconda3/envs/vipergpt/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda110.so\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
      "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so.11.0\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 7.5\n",
      "CUDA SETUP: Detected CUDA version 110\n",
      "CUDA SETUP: Loading binary /home/deepkapha/anaconda3/envs/vipergpt/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda110.so...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eef854ed388345cb9fd3c9e5deb5ce85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/deepkapha/.cache/torch/hub/intel-isl_MiDaS_master\n",
      "Using cache found in /home/deepkapha/.cache/torch/hub/intel-isl_MiDaS_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VISION BACKBONE USE GRADIENT CHECKPOINTING:  False\n",
      "LANGUAGE BACKBONE USE GRADIENT CHECKPOINTING:  False\n",
      "EARLY FUSION ON, USING MHA-B\n",
      "EARLY FUSION ON, USING MHA-B\n",
      "EARLY FUSION ON, USING MHA-B\n",
      "EARLY FUSION ON, USING MHA-B\n",
      "EARLY FUSION ON, USING MHA-B\n",
      "EARLY FUSION ON, USING MHA-B\n",
      "EARLY FUSION ON, USING MHA-B\n",
      "EARLY FUSION ON, USING MHA-B\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from utils import seed_everything\n",
    "from image_patch import ImagePatch, llm_query, best_image_match, distance, bool_to_yesno\n",
    "\n",
    "seed_everything()\n",
    "\n",
    "import ast\n",
    "from vision_processes import forward\n",
    "from torchvision import transforms\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_code(query):\n",
    "    model_name_codex = 'hominiscode'\n",
    "    code = forward(model_name_codex, prompt=query, input_type=\"image\")\n",
    "    code = ast.unparse(ast.parse(code))\n",
    "    return code\n",
    "\n",
    "def load_image(path):\n",
    "    if path.startswith(\"http://\") or path.startswith(\"https://\"):\n",
    "        image = Image.open(requests.get(path, stream=True).raw).convert('RGB')\n",
    "        image = transforms.ToTensor()(image)\n",
    "    else:\n",
    "        image = Image.open(path)\n",
    "        image = transforms.ToTensor()(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = load_image('test/car.jpeg')\n",
    "query = 'What would the founder of the brand of the car on the left say to the founder of the brand of the car on the right?'\n",
    "input_type = \"image\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time  # Importing time to introduce delay between retries, if needed\n",
    "\n",
    "MAX_RETRIES = 3  # Number of retries allowed\n",
    "retry_count = 0\n",
    "\n",
    "while retry_count < MAX_RETRIES:\n",
    "    try:\n",
    "        # Original code logic\n",
    "        code = get_code(query)\n",
    "        code = code.replace('execute_command(image, my_fig, time_wait_between_lines, syntax)', 'execute_command(image)')\n",
    "        exec(compile(code, 'hominiscode', 'exec'), globals())\n",
    "        result = globals()['execute_command'](im)\n",
    "        break  # Exit loop if execution is successful\n",
    "    except AttributeError as e:\n",
    "        retry_count += 1\n",
    "        print(f\"Attempt {retry_count} failed: {e}\")\n",
    "        if retry_count == MAX_RETRIES:\n",
    "            code = None\n",
    "            result = \"Cannot run analysis for this query image pair\"\n",
    "        else:\n",
    "            time.sleep(1)  # Optional delay between retries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def execute_command(image):\n",
      "    car_patches = ImagePatch(image).find('car')\n",
      "    car_patch_left = car_patches[0]\n",
      "    car_patch_right = car_patches[1]\n",
      "    brand_left = car_patch_left.simple_query('What is the name of the brand of this car?')\n",
      "    brand_right = car_patch_right.simple_query('What is the name of the brand of this car?')\n",
      "    left_quote = llm_query(f'What would the founder of {brand_left} say to the founder of {brand_right}?', long_answer=True)\n",
      "    right_quote = llm_query(f'What would the founder of {brand_right} say to the founder of {brand_left}?', long_answer=True)\n",
      "    return f\"The founder of {brand_left} would say: '{left_quote}' and the founder of {brand_right} would say: '{right_quote}'\"\n"
     ]
    }
   ],
   "source": [
    "print(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The founder of ferrari would say: \\'What a fascinating question!\\n\\nLet\\'s imagine the conversation between Enzo Ferrari, the founder of Ferrari, and Ferruccio Lamborghini, the founder of Lamborghini.\\n\\nEnzo Ferrari: \"Ferruccio, my friend, I\\'ve heard you\\'re trying to take on me and my beloved Ferrari. Tell me, what drives your passion for building cars?\"\\n\\nFerruccio Lamborghini: \"Ah, Enzo, it\\'s about innovation, quality, and beating the status quo! You see, as a tractor manufacturer and a lover of fast cars, I knew I had to challenge your dominance in the industry.\"\\n\\nEnzo Ferrari: \"Ha! The audacity! But seriously, Ferruccio, what makes you think you can take on the likes of me? I\\'ve spent decades perfecting the art of building exquisite machines that embody speed, style, and sophistication.\"\\n\\nFerruccio Lamborghini: \"Ah, but Enzo, that\\'s exactly where we differ. You may have perfected the art of building cars for the elite, but I\\'m committed to creating vehicles for the people – cars that are both powerful and accessible. And let\\'s be honest, your V12 engine is impressive, but our mid-mounted V8 engine will give you a run for your money!\"\\n\\nEnzo Ferrari: \"Hmmph! You may have a point there, Ferruccio. But don\\'t think for a second that I\\'ll back down from the challenge! Bring it on, my friend – let\\'s see whose cars reign supreme!\"\\n\\nFerruccio Lamborghini: \"Game on, Enzo! The battle for supremacy has begun!\"\\n\\nAnd so, the legendary rivalry between Ferrari and Lamborghini was born!\\n\\nThis imagined conversation reflects the real-life passion, competitiveness, and mutual respect between Enzo Ferrari and Ferruccio Lamborghini, which fueled the iconic rivalry between their respective car manufacturers.\\' and the founder of lamborghini would say: \\'What a fascinating question!\\n\\nWhile we can\\'t know for certain what Ferruccio Lamborghini would say to Enzo Ferrari, we can make some educated guesses based on their personalities and the history between them.\\n\\nFerruccio Lamborghini was a tractor manufacturer who became interested in high-performance cars after buying a Ferrari 250 GT. He was not satisfied with its performance and took it upon himself to improve it by taking it apart and rebuilding it with modifications. This incident led him to create his own car company, Lamborghini.\\n\\nEnzo Ferrari, on the other hand, was a passionate and intense individual who believed in the superiority of Ferrari over all other car manufacturers. He was known for his strong personality and would often clash with others who disagreed with him.\\n\\nGiven these personalities, here\\'s what Ferruccio Lamborghini might say to Enzo Ferrari:\\n\\n\"Ferrari, I know you\\'re used to being the best, but let me tell you something - you\\'re not invincible. You may have started in a small garage, but I\\'ve built my company from scratch, and I\\'ve done it by listening to what people want. You may think your cars are perfect just the way they are, but I know that\\'s not true. My cars will give yours a run for their money, and maybe even leave them in the dust.\"\\n\\nEnzo Ferrari might respond with something like:\\n\\n\"Lamborghini, you\\'re just a pretender to the throne. You think you can compete with us? Ha! We\\'ve been doing this for decades, and our blood is in these cars. Your tractors may be good, but they\\'ll never be as beautiful or as fast as a Ferrari. And don\\'t even get me started on your \\'super\\' cars - they\\'re just fancy toys compared to the real thing.\"\\n\\nOf course, this is all speculative, but it\\'s fun to imagine what might have been said between these two automotive legends!\\''"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vipergpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
